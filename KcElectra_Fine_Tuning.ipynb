{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb1KNg1PElwbxIR+2NRe3B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hing-9/popup_store/blob/main/KcElectra_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AJqqASjOA45",
        "outputId": "3591545f-398b-4f79-9db3-ccd7b7fb4a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Graduation-Thesis/NER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64FQ8A_rPv0R",
        "outputId": "d1a6a09a-7fac-4d01-c16d-5ee6b2e9bc7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Graduation-Thesis/NER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import random"
      ],
      "metadata": {
        "id": "hlH1y9BTP0Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_to_data(path) :\n",
        "    with open(path, 'r', encoding='UTF-8') as f :\n",
        "        return json.load(f)['data']\n",
        "\n",
        "def data_only_org(data) :\n",
        "    ner_sentences = []\n",
        "    for sentence in data :\n",
        "        if sentence['ner'] : # NER 있는 데이터 발견\n",
        "            tags = sentence['ner']['tags']\n",
        "            org_flag = False\n",
        "            for tag in tags :\n",
        "                if tag['tag'] == 'ORG' :\n",
        "                    org_flag = True\n",
        "                    break\n",
        "            if org_flag :\n",
        "                ner_sentences.append(sentence)\n",
        "    return ner_sentences"
      ],
      "metadata": {
        "id": "c0YKRqoAYvD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_영한 = file_to_data('./일상생활및구어체_영한_train_set.json')\n",
        "data_한영 = file_to_data('./일상생활및구어체_한영_train_set.json')"
      ],
      "metadata": {
        "id": "h9qO9GJgQU7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 결합\n",
        "data = data_영한.copy()\n",
        "data.extend(data_한영.copy())\n",
        "\n",
        "print(f'{len(data)} = {len(data_영한)} + {len(data_한영)}')\n",
        "\n",
        "assert len(data) == len(data_영한)+len(data_한영)"
      ],
      "metadata": {
        "id": "yfMijh6bbJyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabf3473-1a2f-4a2c-c406-c4593418c28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2400307 = 1200307 + 1200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'전체 데이터 개수 : '+str(len(data)))\n",
        "data = data_only_org(data)\n",
        "print(f'NER에 ORG가 포함된 데이터 개수 : '+str(len(data)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44r1Hik5bImk",
        "outputId": "d21b4ab2-8b26-4084-9795-27938f3b5d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 개수 : 2400307\n",
            "NER에 ORG가 포함된 데이터 개수 : 30244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztB0hjuR5r9h",
        "outputId": "c6400722-c1cf-4f30-fd3a-17ecf282ea1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sn': 'ECOAR2T00367',\n",
              " 'data_set': '일상생활및구어체',\n",
              " 'domain': '해외고객과의채팅',\n",
              " 'subdomain': '숙박,음식점',\n",
              " 'en_original': 'I am a professor at BBB1.',\n",
              " 'en': 'I am a professor at BBB1.',\n",
              " 'mt': '저는 BBB1의 교수입니다.',\n",
              " 'ko': '저는 BBB1의 교수입니다.',\n",
              " 'source_language': 'en',\n",
              " 'target_language': 'ko',\n",
              " 'word_count_ko': 3.0,\n",
              " 'word_count_en': 6.0,\n",
              " 'word_ratio': 0.5,\n",
              " 'file_name': '해외고객과의채팅_숙박,음식점.xlsx',\n",
              " 'source': '크라우드 소싱',\n",
              " 'license': 'open',\n",
              " 'style': '구어체',\n",
              " 'included_unknown_words': False,\n",
              " 'ner': {'text': '저는 <ORG>BBB1의</ORG> 교수입니다.',\n",
              "  'tags': [{'tag': 'ORG', 'value': 'BBB1의', 'position': '[3, 8]'}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 이거는 실행해볼 필요는 없음!!\n",
        "# def kind_of_ner_tags(data) :\n",
        "#     result = []\n",
        "#     for sentence in data :\n",
        "#         tags = sentence['ner']['tags']\n",
        "#         for tag in tags :\n",
        "#             result.append(tag['tag'])\n",
        "    \n",
        "#     result = list(set(result))\n",
        "#     return result\n",
        "\n",
        "# def value_for_tag(find_tag, data) :\n",
        "#     result = []\n",
        "#     MAX_CNT = 10\n",
        "#     cnt = 0\n",
        "\n",
        "#     for sentence in data :\n",
        "#         tags = sentence['ner']['tags']\n",
        "#         for tag in tags :\n",
        "#             if tag['tag'] == find_tag :\n",
        "#                 result.append(tag['value'])\n",
        "#                 cnt += 1\n",
        "        \n",
        "#         if cnt >= MAX_CNT :\n",
        "#                 break;\n",
        "    \n",
        "#     return result\n",
        "\n",
        "\n",
        "# tags = kind_of_ner_tags(data)\n",
        "# print(f'모든 데이터에서 검출된 NER TAGS : {tags}')\n",
        "# print()\n",
        "\n",
        "# for tag in tags :\n",
        "#     print(f'==== TAG : {tag}====')\n",
        "#     print(value_for_tag(tag, data))"
      ],
      "metadata": {
        "id": "HD_7et8_a-ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 혹시나.. 팝업이 들어간 데이터를 추출해보자\n",
        "# def find_popup(data) : \n",
        "#     result = []\n",
        "#     for sentence in data :\n",
        "#         if '팝업' in sentence['ko'] :\n",
        "#             result.append(sentence['ko'])\n",
        "#         # elif '스토어' in sentence['ko'] :\n",
        "#         #     result.append(sentence['ko'])\n",
        "#     return result\n",
        "\n",
        "# find_popup(data)"
      ],
      "metadata": {
        "id": "3MvKOhf5htJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ORG 태그에 브랜드명을 넣어 학습시키는게 정당해보임.\n",
        "# 브랜드명은 소상공인 데이터\n",
        "brand_data = pd.read_csv('./소상공인시장진흥공단_상가(상권)정보_서울_202212.csv', encoding='UTF-8')\n",
        "brand_names = brand_data['상호명'].values"
      ],
      "metadata": {
        "id": "XBlHlNC8eLYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 브랜드명을 입력\n",
        "rnd_idx = random.randrange(0, len(brand_names))\n",
        "brand_names[rnd_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "bvsiYxLskZCv",
        "outputId": "4e4df5c0-6e1f-4d3c-d8c6-92454623642d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'아모레카운셀러'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def random_brand_transfer(raw_data) :\n",
        "    data = raw_data.copy()\n",
        "    tokens_arr = []\n",
        "    tags_arr  = []\n",
        "\n",
        "    for idx, sentence in enumerate(data) :\n",
        "\n",
        "        # NER 없는 데이터면 Pass\n",
        "        if not sentence['ner'] :\n",
        "            continue\n",
        "        \n",
        "        tokens_sentence = []\n",
        "        tags_sentence = []\n",
        "\n",
        "        old_org_list = []\n",
        "        chg_org_list = []\n",
        "\n",
        "        tags = sentence['ner']['tags']\n",
        "\n",
        "        # print(f'{idx} : {sentence[\"ko\"]}')\n",
        "\n",
        "        for tag in tags :\n",
        "            if tag['tag'] == 'ORG' :\n",
        "                \n",
        "                # 브랜드 이름 랜덤 추출\n",
        "                rnd_idx = random.randrange(0, len(brand_names))\n",
        "                chg_org_list.append(brand_names[rnd_idx])\n",
        "\n",
        "                # 전체 문장 치환\n",
        "                # start_index = sentence['ko'].index(tag['value'])\n",
        "                # end_index = start_index+len(tag['value'])\n",
        "                # tag['value'] = chg_org\n",
        "                positions = tag['position'][1:-1].split(',')\n",
        "                start_index = int(positions[0])\n",
        "                end_index = int(positions[1])\n",
        "                old_org_list.append(sentence['ko'][start_index:end_index])\n",
        "\n",
        "        if len(chg_org_list) < 1 :\n",
        "            continue\n",
        "\n",
        "        assert len(old_org_list) == len(chg_org_list)\n",
        "\n",
        "        for i in range(len(old_org_list)) :\n",
        "            old_org_nm = old_org_list[i]\n",
        "            chg_org_nm = chg_org_list[i]\n",
        "\n",
        "            target = sentence['ko']\n",
        "            target = target.replace(old_org_nm, chg_org_nm)\n",
        "            sentence['ko'] = target\n",
        "        \n",
        "        # print(f'{idx} : {sentence[\"ko\"]}')\n",
        "\n",
        "        # token과 tag를 Setting\n",
        "        tokens_sentence = list(sentence['ko'])\n",
        "\n",
        "        for i in range(len(tokens_sentence)) :\n",
        "            tags_sentence.append('O')\n",
        "\n",
        "        assert len(tokens_sentence) == len(tags_sentence)\n",
        "\n",
        "        for org_name in chg_org_list :\n",
        "\n",
        "            start_idx = -1\n",
        "            while True :\n",
        "                start_idx = sentence['ko'].find(org_name, start_idx+1)\n",
        "\n",
        "                if start_idx == -1 :\n",
        "                    break;\n",
        "                \n",
        "                end_idx = start_idx + len(org_name)\n",
        "\n",
        "                for i in range(start_idx, end_idx) :\n",
        "                    if i > start_idx :\n",
        "                        tag_nm = 'I-ORG'\n",
        "                    else :\n",
        "                        tag_nm = 'B-ORG'\n",
        "                    \n",
        "                    tags_sentence[i] = tag_nm\n",
        "\n",
        "        result_tokens_sentence = []\n",
        "        for token in tokens_sentence :\n",
        "            tmp = token.replace(' ','_')\n",
        "            result_tokens_sentence.append(tmp)\n",
        "            \n",
        "        # print(tokens_sentence)\n",
        "        # print(tags_sentence)\n",
        "        # print(f'tokens : {len(tokens_sentence)}, tags : {len(tags_sentence)}')\n",
        "\n",
        "        tokens_arr.append(result_tokens_sentence)\n",
        "        tags_arr.append(tags_sentence)\n",
        "\n",
        "    return tokens_arr, tags_arr"
      ],
      "metadata": {
        "id": "bz2JanhNkyyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens, tags = random_brand_transfer(data)"
      ],
      "metadata": {
        "id": "2hLAvLWBmYpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[2140]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn65zK7y6kI1",
        "outputId": "dcb407e0-0340-459f-e47c-0d35cb2bf351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sn': 'EISWR2F10901',\n",
              " 'data_set': '일상생활및구어체',\n",
              " 'domain': '해외영업',\n",
              " 'subdomain': '도소매유통',\n",
              " 'en_original': 'However, users singled out FFF and we decide to launched it after revamping it.',\n",
              " 'en': 'However, users singled out FFF and we decide to launched it after revamping it.',\n",
              " 'mt': '하지만 유저들이 FFF를 꼽았고, 저희는 FFF를 개편하여 출시하기로 결정했습니다.',\n",
              " 'ko': '하지만, 사용자들이 윤기나는청소를 골랐고 저희는 윤기나는청소를 개편하여 출시하기로 했습니다.',\n",
              " 'source_language': 'en',\n",
              " 'target_language': 'ko',\n",
              " 'word_count_ko': 9.0,\n",
              " 'word_count_en': 14.0,\n",
              " 'word_ratio': 0.643,\n",
              " 'file_name': '해외영업_도소매유통.xlsx',\n",
              " 'source': '크라우드 소싱',\n",
              " 'license': 'open',\n",
              " 'style': '구어체',\n",
              " 'included_unknown_words': False,\n",
              " 'ner': {'text': '하지만, 사용자들이 <ORG><ORG>FFF</ORG></ORG>를 골랐고 저희는 <ORG><ORG>FFF</ORG></ORG>를 개편하여 출시하기로 했습니다.',\n",
              "  'tags': [{'tag': 'ORG', 'value': 'FFF', 'position': '[11, 14]'},\n",
              "   {'tag': 'ORG', 'value': 'FFF', 'position': '[24, 27]'}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8EKeyPB3HtoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}